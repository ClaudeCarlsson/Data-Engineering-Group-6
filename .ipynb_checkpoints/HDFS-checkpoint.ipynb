{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df6aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import trim, regexp_replace, lower, explode, trim, split\n",
    "from pyspark.sql.types import StructType, StructField, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abc3c91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/03/12 01:00:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark_session = SparkSession.builder\\\n",
    ".master(\"spark://192.168.2.97:7077\") \\\n",
    ".appName(\"claude_carlsson_hdfs\")\\\n",
    ".config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    ".config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    ".config(\"spark.shuffle.service.enabled\", True)\\\n",
    ".config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    ".config(\"spark.cores.max\", 5)\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b04a1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_body_to_string(json_filename):\n",
    "    df = spark_session.read.json(json_filename)\n",
    "\n",
    "    my_df_lower = df.select(lower(\"body\").alias(\"lowercase_body\"))\n",
    "\n",
    "    charachters_to_delete = \"[\\.,\\[\\]\\(\\):_\\-!?\\'\\+=;/&{}@$#*\\\"\\\\\\\\%><|~¨´¤]\"\n",
    "\n",
    "    my_df_clean = my_df_lower.withColumn(\"lowercase_body\", regexp_replace(my_df_lower.lowercase_body, charachters_to_delete, \"\"))\n",
    "\n",
    "    my_df_words = my_df_clean.select(explode(split(\"lowercase_body\", \"\\s+\")).alias(\"word\"))\n",
    "\n",
    "    return my_df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f83d8919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_all_years = parse_json_body_to_string(\"hdfs://192.168.2.97:50000/user/ubuntu/RC_2006-01.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b692509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|       word|\n",
      "+-----------+\n",
      "|      early|\n",
      "|       2006|\n",
      "|          a|\n",
      "|   probable|\n",
      "|       date|\n",
      "|         if|\n",
      "|        you|\n",
      "|        are|\n",
      "|      going|\n",
      "|         to|\n",
      "|       post|\n",
      "|  something|\n",
      "|       that|\n",
      "|        has|\n",
      "|          a|\n",
      "|       link|\n",
      "|         to|\n",
      "|        the|\n",
      "|   original|\n",
      "|     author|\n",
      "|        why|\n",
      "|        not|\n",
      "|       just|\n",
      "|       post|\n",
      "|        the|\n",
      "|   original|\n",
      "|    instead|\n",
      "|         of|\n",
      "|   someones|\n",
      "|       copy|\n",
      "|  microsoft|\n",
      "|      hates|\n",
      "|        its|\n",
      "|        own|\n",
      "|   products|\n",
      "|        who|\n",
      "|       knew|\n",
      "|       this|\n",
      "|      looks|\n",
      "|interesting|\n",
      "|        but|\n",
      "|        its|\n",
      "|    already|\n",
      "|      aired|\n",
      "|        and|\n",
      "|        its|\n",
      "|        not|\n",
      "|       like|\n",
      "|     theres|\n",
      "|  streaming|\n",
      "|      video|\n",
      "|         so|\n",
      "|      whats|\n",
      "|        the|\n",
      "|      point|\n",
      "|          i|\n",
      "|       have|\n",
      "|    nothing|\n",
      "|        but|\n",
      "|       good|\n",
      "|     things|\n",
      "|         to|\n",
      "|        say|\n",
      "|      about|\n",
      "|       dell|\n",
      "|       tech|\n",
      "|    support|\n",
      "|       many|\n",
      "|          a|\n",
      "|       time|\n",
      "|        ive|\n",
      "|     called|\n",
      "|         in|\n",
      "|          a|\n",
      "|     faulty|\n",
      "|       part|\n",
      "|        and|\n",
      "|        had|\n",
      "|        the|\n",
      "|replacement|\n",
      "|         at|\n",
      "|        the|\n",
      "|      front|\n",
      "|       door|\n",
      "|         in|\n",
      "|        two|\n",
      "|       days|\n",
      "|       with|\n",
      "|          a|\n",
      "|        box|\n",
      "|         to|\n",
      "|       ship|\n",
      "|        the|\n",
      "|        old|\n",
      "|        one|\n",
      "|       back|\n",
      "|      first|\n",
      "|      class|\n",
      "|    service|\n",
      "|         if|\n",
      "+-----------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all_years.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94aef8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcd7db3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
